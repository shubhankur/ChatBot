{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhGiyUPJaZCR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "! pip install transformers==4.27.4\n",
        "\n",
        "! pip install torchtext==0.10.1\n",
        "\n",
        "import torch\n",
        "device = torch.device(\"cuda\")\n",
        "torch.cuda.init()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "from transformers import GPT2Tokenizer, GPT2Config, GPT2LMHeadModel, TextDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/gdrive/My Drive/model/chitchat_generator.pt\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', padding_side='left')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))"
      ],
      "metadata": {
        "id": "wLY0H4dAa6jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = '/content/gdrive/My Drive/dataset/combined_test.txt'"
      ],
      "metadata": {
        "id": "0Kvyj-0Qbe26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "BDuAGs3Gb4Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def getResponse(input_text, model,tokenizer, device):\n",
        "  input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "  if(len(input_ids)<=0):\n",
        "    print(input_text)\n",
        "    return None\n",
        "  input_ids = input_ids.to(device)\n",
        "  model = model.to(device)\n",
        "  output_ids = model.generate(input_ids,pad_token_id=tokenizer.eos_token_id, max_length=100,early_stopping=True)\n",
        "  output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "  messages = output_text.split(\"\\n\")\n",
        "  first_bot_response = None\n",
        "  for message in messages:\n",
        "    if message.startswith(\"Bot:\"):\n",
        "        first_bot_response = message.strip()\n",
        "        break\n",
        "  return first_bot_response"
      ],
      "metadata": {
        "id": "GMXMW0ofbpZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(getResponse(\"User: Hello, I am feeling very sad\",model, tokenizer, device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBhx6Jj1gv9W",
        "outputId": "0a932559-aeba-43be-9dbb-0510eedc4dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot: I am sorry to hear that. I am sure you are feeling better.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/gdrive/My Drive/dataset/combined_test.txt', 'r') as f:\n",
        "    test_data = f.readlines()"
      ],
      "metadata": {
        "id": "YryGXsmTeUnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4knbvpkz_7O",
        "outputId": "b73b4993-f647-4a95-bcd2-74b3cf4a95d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36273"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare(test_data):\n",
        "  input = {}\n",
        "  response = {}\n",
        "  conv_id = 1\n",
        "  idx = 1\n",
        "  for i in range(len(test_data)):\n",
        "    input[idx]=\"\"\n",
        "    response[idx]=\"\"\n",
        "    if(test_data[i]==\"\\n\" or test_data[i]=='\\n'):\n",
        "      idx+=1\n",
        "  for data in test_data:\n",
        "    if(conv_id>=idx):\n",
        "      break\n",
        "    if(data.startswith(\"User\")):\n",
        "      input[conv_id]+= data \n",
        "    elif(data.startswith(\"Bot\")):\n",
        "      response[conv_id]+=data\n",
        "    else:\n",
        "      conv_id+=1\n",
        "  return input,response"
      ],
      "metadata": {
        "id": "RNIyc7UBecLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input, response = prepare(test_data)"
      ],
      "metadata": {
        "id": "f28x0-q2ekBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response2=response.copy()"
      ],
      "metadata": {
        "id": "SYPXYumQlq_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def getResponses(input, response, model,tokenizer, device):\n",
        "  generated_response = {}\n",
        "  with open(\"/content/gdrive/My Drive/dataset/generated_responses.json\", 'a') as f:\n",
        "    for idx, text in tqdm(input.items()):\n",
        "      value = getResponse(text, model,tokenizer, device)\n",
        "      if(value==None):\n",
        "        response2[idx]=\"None\"\n",
        "      generated_response[idx] = value\n",
        "      f.write(str(idx)+ \":\" )\n",
        "      f.write(str(value))\n",
        "      f.write(\"\\n\")\n",
        "  return generated_response"
      ],
      "metadata": {
        "id": "RfQXtbu_emF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_response = getResponses(input, response, model,tokenizer, device)"
      ],
      "metadata": {
        "id": "96S47G3-gTlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# open file for writing\n",
        "with open(\"/content/gdrive/My Drive/dataset/generated_responses2.json\", \"w\") as outfile:\n",
        "    # write dictionary to file in JSON format\n",
        "    json.dump(generated_response, outfile)"
      ],
      "metadata": {
        "id": "c4TiLTNDMF5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/gdrive/My Drive/dataset/generated_responses2.json\", \"r\") as rf:\n",
        "  data = rf.readlines()\n",
        "len(data)"
      ],
      "metadata": {
        "id": "hWD6hqkSiRpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_response = []\n",
        "for res in data:\n",
        "  res.strip()\n",
        "  if(\"Bot\" in res):\n",
        "    res = res[res.find(\"Bot\"):len(res)-1]\n",
        "  formatted_response.append(res)"
      ],
      "metadata": {
        "id": "8ag6OGiWiSlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install bert-score\n"
      ],
      "metadata": {
        "id": "e6YLdyW0v4QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bert_score import score\n",
        "P, R, F1 = score(formatted_response, list(response.values()), lang=\"en\", verbose=True)"
      ],
      "metadata": {
        "id": "8jhZ6zUfwJs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(P.mean().item())\n",
        "print(R.mean().item())\n",
        "print(F1.mean().item())"
      ],
      "metadata": {
        "id": "ApKfBv_BxYBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "bleu_score = corpus_bleu(formatted_response, list(response.values()))\n",
        "bleu_score"
      ],
      "metadata": {
        "id": "WMAZvfCpxru5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install rouge"
      ],
      "metadata": {
        "id": "WDDWQ5R20hDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(formatted_response, list(response.values()), avg=True)"
      ],
      "metadata": {
        "id": "6ymKgsgp0aQl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}